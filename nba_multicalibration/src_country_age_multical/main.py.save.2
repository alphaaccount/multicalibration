import pandas as pd
import numpy as np
import argparse, os, math
import matplotlib as mpl
import matplotlib.pyplot as plt
from time import process_time
import random
from data_preparation import synthetic, LSAT
from visualization.plots import plotKDEPerGroup
from cfa.cfa import ContinuousFairnessAlgorithm
from evaluation.fairnessMeasures import groupPercentageAtK
from evaluation.relevanceMeasures import pak, ndcg_score


def dcg_at_k(r, k):
    r = np.asfarray(r)[:k]
    if r.size != k:
        raise ValueError('Ranking List length < k')    
    return np.sum((2**r - 1) / np.log2(np.arange(2, r.size + 2)))


def ndcg_at_k(r, k):
    sort_r = sorted(r,reverse = True)
    idcg = dcg_at_k(sort_r, k)
    if not idcg:
        print('.', end=' ')
        return 0.
    return dcg_at_k(r, k) / idcg



def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def createSyntheticData(size):
    nonProtectedAttributes = ['score']
    protectedAttributes = {"gender": 2, "ethnicity": 3}
    creator = synthetic.SyntheticDatasetCreator(
        size, protectedAttributes, nonProtectedAttributes)
    creator.createTruncatedIntegerScoresNormallyDistributed(1, 101)
    creator.sortByColumn('score')
    creator.writeToCSV('../data/synthetic/dataset.csv',
                       '../data/synthetic/groups.csv')
    groupNames = {"[0 0]":"Group [0 0]",
                  "[0 1]":"Group [0 1]",
                  "[0 2]":"Group [0 2]",
                  "[1 0]":"Group [1 0]",
                  "[1 1]":"Group [1 1]",
                  "[1 2]":"Group [1 2]"}
    plotKDEPerGroup(creator.dataset, creator.groups, 'score',
                    '../data/synthetic/scoreDistributionPerGroup.png', groupNames)
#     dataset = pd.read_csv('../data/synthetic/dataset.csv', sep=',')
#     groups = pd.read_csv('../data/synthetic/groups.csv', sep=',')
#
#     plotKDEPerGroup(dataset, groups, 'score',
#                     '../data/synthetic/scoreDistributionPerGroup.png', groupNames)
def createLSATDatasets():
    creator = LSAT.LSATCreator('../data/LSAT/law_data.csv.xlsx')
    #prepare the independent set data here write code for that 

    creator.prepareAllData()
    creator.writeToCSV('../data/LSAT/all/allLSAT.csv','../data/LSAT/all/allGroups.csv')
    print("O hello")
    #groupNames = {"[0]":"Male","[1]":"Female","[2]":"White", "[3]":"Amerindian", "[4]":"Asian", "[5]":"Black", "[6]":"Hispanic", "[7]":"Mexican", "[8]":"Other">

   


    # all ethnicity in one dataset
    creator.prepareAllRaceData()
    creator.writeToCSV('../data/LSAT/allRace/allEthnicityLSAT.csv',
                       '../data/LSAT/allRace/allEthnicityGroups.csv')
    groupNames = {"[0]":"White",
                  "[1]":"Amerindian",
                  "[2]":"Asian",
                  "[3]":"Black",
                  "[4]":"Hispanic",
                  "[5]":"Mexican",
                  "[6]":"Other",
                  "[7]":"Puertorican"}
    #plotKDEPerGroup(creator.dataset, creator.groups, 'LSAT','../data/LSAT/allRace/scoreDistributionPerGroup_AllRace_LSAT', groupNames)
    #plotKDEPerGroup(creator.dataset, creator.groups, 'ZFYA','../data/LSAT/allRace/scoreDistributionPerGroup_AllRace_ZFYA', groupNames)

    # gender dataset
    creator.prepareGenderData()
    creator.writeToCSV('../data/LSAT/gender/genderLSAT.csv',
                              '../data/LSAT/gender/genderGroups.csv')
    groupNames = {"[0]":"Male",
                  "[1]":"Female"}
    #plotKDEPerGroup(creator.dataset, creator.groups, 'LSAT','../data/LSAT/gender/scoreDistributionPerGroup_Gender_LSAT', groupNames)
    #plotKDEPerGroup(creator.dataset, creator.groups, 'ZFYA''../data/LSAT/gender/scoreDistributionPerGroup_Gender_ZFYA', groupNames)

def rerank_with_cfa(score_stepsize, thetas, result_dir, pathToData, pathToGroups, qual_attr, group_names):
    data = pd.read_csv(pathToData, sep=',')
    groups = pd.read_csv(pathToGroups, sep=',')
    #print("Thetas are", thetas)
    print("data before", data)
    m = 40
    n = len(data)
    data1 = np.zeros((m,n))
    for i in range(len(data)):
        for j in range(2):
          for k in range(2):
            if data.iloc[i,1]==j and data.iloc[i,4]==k :
              data1[2*j+k][i] = 1

        for j in range(6):
          for k in range(6):
            if data.iloc[i,2]==j and data.iloc[i,5]==k :
              data1[6*j+k+4][i] = 1   #begins at 4

    sizes = np.zeros(m)
    max_size=0
    for i in range(m):
        count=0
        for j in range(n):
            if data1[i][j]==1:
                count=count+1 
        if count>max_size:
            max_size=count
        sizes[i]=count
    print(sizes)    

    data2 = data.copy()


    node_pairs = data[['node0','node1']]
    print("node_pairs are", node_pairs)
    del data['node0']
    del data['node1']
    print("data after", data)
    print("group names are", group_names)
    # check that we have a theta for each group
    if groups.shape[0] != len(thetas):
        raise ValueError(
            "invalid number of thetas, should be {numThetas} Specify one theta per group.".format(numThetas=groups.shape[0]))

    regForOT = 5e-3
    t = process_time()
    cfa = ContinuousFairnessAlgorithm(data,
                                      groups,
                                      group_names,
                                      qual_attr,
                                      score_stepsize,
                                      thetas,
                                      regForOT,
                                      path=result_dir,
                                      plot=True)
    result = cfa.run()
    print("result is")
    print(result)
    fair_scores = result['fairScore']
    score = result['score']

    m = 40
    gr_ind = [ [] for _ in range(m) ]
    grf_ind = [ [] for _ in range(m) ]

    #count = np.zeros(r, dtype=int)

    DP_list_ind = []
    DPf_list_ind = []
    n = len(result)    
    for i in range(n):
          for j in range(2):
            for k in range(2):
              if int(data2.iloc[i,1]) == j and int(data2.iloc[i,4]) == k:
                gr_ind[2*j+k].append(data2.iloc[i,6])
                grf_ind[2*j+k].append(fair_scores.iloc[i])

          for j in range(6):
            for k in range(6):
              if int(data2.iloc[i,2])==j and int(data2.iloc[i,5])==k :
                gr_ind[6*j+k+4].append(data2.iloc[i,6])   #begins at 4
                grf_ind[6*j+k+4].append(fair_scores.iloc[i])

    for i in range(m):
      if sizes[i] != 0:
        DP_list_ind.append(np.sum(sigmoid(np.asarray(gr_ind[i])))/sizes[i])
        DPf_list_ind.append(np.sum(np.asarray(grf_ind[i]))/sizes[i])



    print(max(DP_list_ind), min(DP_list_ind))
    print(max(DPf_list_ind), min(DPf_list_ind))
    DP_ind = max(DP_list_ind)-min(DP_list_ind)
    DPf_ind = max(DPf_list_ind)-min(DPf_list_ind)
    print("Demogrphic Parity is without/with fair of Independent Groups", DP_ind, DPf_ind)


    m = 20
    for n in [116]:

        gr = [ [] for _ in range(n) ]
        grf = [ [] for _ in range(n) ]
    # [0. 0. 0. 0.]  [1. 0. 0. 0.]  [0. 0. 1. 0.]  [1. 0. 1. 0.]  # now we have 112 groups so write a general program for that.
        count = np.zeros(n, dtype=int)
    #gro = [[],[],[],[]]
    #grof = [[],[],[],[]]

        DP_list = []
        DPf_list = []
    ## there are 4 groups find the pair scores for eachgroup
    ## there is a small issue here there pairs are male-male or something similar female-female pairs 
    ## compute  DDP using both the formula, with and without OT then only use of OT will be clear.

        for i in range(len(result)):
             for j in range(n):
                  if(result.iloc[i,0] == groups.iloc[j,0] and result.iloc[i,1] == groups.iloc[j,1] and result.iloc[i,2] == groups.iloc[j,2] and result.iloc[i,3]== groups.iloc[j,3]):
                       gr[j].append(result.iloc[i,4])
                       grf[j].append(result.iloc[i,5])
                       count[j] = count[j]+1

        for i in range(n):
             if count[i] != 0:
                  DP_list.append(np.sum(sigmoid(np.asarray(gr[i])))/count[i])
                  DPf_list.append(np.sum(sigmoid(np.asarray(grf[i])))/count[i])

        DP = max(DP_list)-min(DP_list)
        DPf = max(DPf_list)-min(DPf_list)
        print("Demogrphic Parity is without/with fair of Intersectional Groups", DP, DPf)

    result['node0'] = node_pairs['node0']
    result['node1'] = node_pairs['node1']
    print(result)
    M = 400
    k = 10
    accum_ndcg = 0
    node_cnt = 0
    accum_ndcg_u = 0
    node_cnt_u = 0

    adj_mtx = np.zeros((M,M))
    # load the adjacency matrix of size MxM of training or testing set

    print('loading data ...')
    with open('pokec-z_edge.csv', 'r') as fin:
        lines = fin.readlines()
        idx = 0 
        for line in lines:
            if idx == 0: 
                idx += 1
                continue
            eachline = line.strip().split(',')
            scr_node = int(eachline[0])
            dst_node = int(eachline[1])
            weight = float(eachline[2])
            adj_mtx[scr_node, dst_node] = weight 
            adj_mtx[dst_node, scr_node] = weight 
            idx += 1

    adj_mtx_fair = np.zeros((M,M))
    adj_mtx_unfair = np.zeros((M,M))
    selected_pairs = np.zeros((M,M))

    for i in range(len(result)):
        adj_mtx_unfair[int(result.iloc[i,6])][int(result.iloc[i,7])] = result.iloc[i,4]
        selected_pairs[int(result.iloc[i,6])][int(result.iloc[i,7])] = 1
        adj_mtx_fair[int(result.iloc[i,6])][int(result.iloc[i,7])] = result.iloc[i,5]

    print(adj_mtx_fair)
    print(np.count_nonzero(adj_mtx_fair))
    print('Utility evaluation (link prediction)')
    s = random.sample(range(M),50000)
    for node_id in s:
        node_edges = adj_mtx[node_id]
        test_pos_nodes = []
        neg_nodes = []
        for i in range(M):
            if selected_pairs[node_id][i]==1:
                 if adj_mtx[node_id][i]>0:
                     test_pos_nodes.append(i)
                 else:
                     neg_nodes.append(i)
 
        #pred_edges_fair.append(adj_mtx_fair[node_id][i])
        #pred_edges_unfair.append(adj_mtx_fair[node_id][i])

        #pos_nodes = np.where(node_edges>0)[0]
        #num_pos = len(pos_nodes)
        #num_test_pos = int(len(pos_nodes) / 10) + 1
        #test_pos_nodes = pos_nodes[:num_test_pos]
        #num_pos = len(test_pos_nodes)
        #print(num_pos)

        #if num_pos == 0 or num_pos >= 100:
        #    continue
        #neg_nodes = np.random.choice(np.where(node_edges == 0)[0], 100-num_pos, replace=False)
        num_pos = len(test_pos_nodes)
        all_eval_nodes = np.concatenate((test_pos_nodes, neg_nodes)) 
        all_eval_edges = np.zeros(20)  # because each node has 20 neighbors in the set
        all_eval_edges[:num_pos] = 1
        #print(all_eval_edges)

       
        #in pred_edges all positive edges should be before and then negative edge sores
        edges = []
        pred_edges_fair_pos = []
        pred_edges_fair_neg = []

        pred_edges_unfair_pos = []
        pred_edges_unfair_neg = []

        for i in range(M):
            if selected_pairs[node_id][i]==1:
                 if adj_mtx[node_id][i]>0:
                     pred_edges_fair_pos.append(adj_mtx_fair[node_id][i])
                     pred_edges_unfair_pos.append(adj_mtx_unfair[node_id][i])
                 else:
                     pred_edges_fair_neg.append(adj_mtx_fair[node_id][i])
                     pred_edges_unfair_neg.append(adj_mtx_unfair[node_id][i])

        #print(pred_edges_fair_pos)
        pred_edges_fair = np.concatenate((np.array(pred_edges_fair_pos),np.array(pred_edges_fair_neg)))
        pred_edges_unfair = np.concatenate((np.array(pred_edges_unfair_pos),np.array(pred_edges_unfair_neg)))
      
        #print(len(pred_edges_unfair))
        #print(len(pred_edges_fair))


        if len(pred_edges_unfair) >=k:
            #pred_edges_unfair = np.array(pred_edges_unfair)
            rank_pred_keys = np.argsort(pred_edges_unfair)[::-1]
            ranked_node_edges = all_eval_edges[rank_pred_keys]
            ndcg_u = ndcg_at_k(ranked_node_edges, k)
            if ndcg_u != 0.0:
                 accum_ndcg_u += ndcg_u
                 print(ndcg_u, node_cnt_u)
                 node_cnt_u += 1

        if len(pred_edges_fair) >=k:
            #pred_edges_fair = np.array(pred_edges_fair)
            rank_pred_keys = np.argsort(pred_edges_fair)[::-1]
            ranked_node_edges = all_eval_edges[rank_pred_keys]
            ndcg = ndcg_at_k(ranked_node_edges, k)
            if ndcg != 0.0:
                 accum_ndcg += ndcg
                 node_cnt += 1
        
 
    '''

    for node_id in range(M):
        node_edges = adj_mtx[node_id]
        pos_nodes = np.where(node_edges>0)[0]
        # num_pos = len(pos_nodes)
        num_test_pos = int(len(pos_nodes) / 10) + 1
        test_pos_nodes = pos_nodes[:num_test_pos]
        num_pos = len(test_pos_nodes)
        #print(num_pos)
        if num_pos == 0 or num_pos >= 100:
            continue
        neg_nodes = np.random.choice(np.where(node_edges == 0)[0], 100-num_pos, replace=False)
        all_eval_nodes = np.concatenate((test_pos_nodes, neg_nodes)) 
        all_eval_edges = np.zeros(100)
        all_eval_edges[:num_pos] = 1
        #print(all_eval_nodes)
        pred_edges = []
        pred_edges_unfair = []
        for i in all_eval_nodes:
            if adj_mtx_fair[node_id][i] != 0:
                 pred_edges.append(i)
            if adj_mtx_unfair[node_id][i] != 0:
                 pred_edges_unfair.append(i)
        if len(pred_edges)>=3: print(pred_edges)
        
        #pred_edges = np.dot(embedding[node_id], embedding[all_eval_nodes].T)
        if len(pred_edges_unfair) >=k:
            pred_edges_unfair = np.array(pred_edges_unfair)
            rank_pred_keys = np.argsort(pred_edges_unfair)[::-1]
            ranked_node_edges = all_eval_edges[rank_pred_keys]
            ndcg_u = ndcg_at_k(ranked_node_edges, k)
            accum_ndcg_u += ndcg_u
            node_cnt_u += 1

        if len(pred_edges) >=k:
            pred_edges = np.array(pred_edges)
            rank_pred_keys = np.argsort(pred_edges)[::-1]
            ranked_node_edges = all_eval_edges[rank_pred_keys]
            ndcg = ndcg_at_k(ranked_node_edges, k)
            accum_ndcg += ndcg
            node_cnt += 1

    '''
    score = accum_ndcg/node_cnt
    score_u = accum_ndcg_u/node_cnt_u

    print('-- ndcg of link prediction for fair score:{}'.format(score))
    print('-- ndcg of link prediction for unfair score:{}'.format(score_u))

    elapsed_time = process_time() - t
    result.to_csv(result_dir + "resultData.csv")

    print('running time: ' + str(elapsed_time), file=open(result_dir + "runtime.txt", "a"))

def parseThetas(thetaString):
    thetas = np.array(thetaString.split(","))
    floatThetas = [float(i) for i in thetas]
    return floatThetas


def precisionAtKPrep(origData, fairData, qualAttr):
    origSorting = origData.sort_values(by=[qualAttr, 'uuid'], ascending=[False, True])
    origSorting = origSorting.reset_index(drop=True)

    fairSorting = fairData.sort_values(by=['fairScore', 'uuid'], ascending=[False, True])
    fairSorting = fairSorting.reset_index(drop=True)

    return origSorting['uuid'].values, fairSorting['uuid'].values


def ndcgPrep(fairData):
    ndcgData = fairData.sort_values(by=['fairScore', 'uuid'], ascending=[False, True])
    ndcgData = ndcgData.reset_index(drop=True)
    return ndcgData


def evaluateRelevance(origData, fairData, result_dir, qualAttr, stepsize, calcResult=0):

    ndcgAtK = np.empty(int(math.ceil(fairData.shape[0] / stepsize)))
    precisionAtK = np.empty(int(math.ceil(fairData.shape[0] / stepsize)))
    kAtK = np.empty(int(math.ceil(fairData.shape[0] / stepsize)))
    index = 0

    ndcgData = ndcgPrep(fairData)
    pakOrigData, pakFairData = precisionAtKPrep(origData, fairData, qualAttr)
    for k in range(0, fairData.shape[0], stepsize):
        print(k)
        # relevance measures
        np.put(ndcgAtK,
               index,
               ndcg_score(ndcgData[qualAttr].values, ndcgData['fairScore'].values, k, gains="linear"))
        np.put(precisionAtK,
               index,
               pak(k + 1, pakOrigData, pakFairData))
        np.put(kAtK,
               index,
               k)
        index += 1

    # save result to disk if wanna change plots later
    performanceData = np.stack((kAtK, ndcgAtK, precisionAtK), axis=-1)
    performanceDataframe = pd.DataFrame(performanceData, columns=['pos', 'ndcg', 'P$@$k'])
    performanceDataframe = performanceDataframe.set_index('pos')
    performanceDataframe.to_csv(result_dir + "relevanceEvaluation_stepsize=" + str(stepsize) + ".csv")
    performanceDataframe = pd.read_csv(result_dir + "relevanceEvaluation_stepsize=" + str(stepsize) + ".csv")
    performanceDataframe = performanceDataframe.set_index('pos')
    print("performance dataframe is")
    print(performanceDataframe)

    # plot results
    mpl.rcParams.update({'font.size': 24, 'lines.linewidth': 3,
                         'lines.markersize': 15, 'font.family': 'Times New Roman'})
    mpl.rcParams['ps.useafm'] = True
    mpl.rcParams['pdf.use14corefonts'] = True
    mpl.rcParams['text.usetex'] = True
    ax = performanceDataframe.plot(y=['ndcg', 'P$@$k'],
                                   kind='line',
                                   use_index=True,
                                   yticks=np.arange(0.0, 1.1, 0.2),
                                   rot=45)
    ax.legend(bbox_to_anchor=(1.05, 1),
              loc=2,
              borderaxespad=0.)  # , labels=self.__groupNamesForPlots)
    ax.set_xlabel("ranking position")
    ax.set_ylabel("relevance score")
    #plt.savefig(result_dir + "relevanceEvaluation_stepsize=" + str(stepsize) + ".png", dpi=100, bbox_inches='tight')


def evaluateFairness(data, groups, groupNames, result_dir, stepsize):
    """
    evaluates fairness of rankings resulting from cfa algorithm
    """
    index = 0
    percAtK = np.empty(shape=(int(math.ceil(data.shape[0] / stepsize)), len(groups)))
    kAtK = np.empty(int(math.ceil(data.shape[0] / stepsize)))
    data = ndcgPrep(data)
    for k in range(0, data.shape[0], stepsize):
        print(k)
        percAtK[index] = groupPercentageAtK(data.head(k + 1), groups)
        kAtK[index] = k
        index += 1

    # save result to disk if wanna change plots later
    fairnessData = np.c_[kAtK.T, percAtK]
    colNames = ['pos'] + groupNames
    fairnessDataframe = pd.DataFrame(fairnessData, columns=colNames)
    fairnessDataframe = fairnessDataframe.set_index('pos')
    fairnessDataframe.to_csv(result_dir + "fairnessEvaluation_stepsize=" + str(stepsize) + ".csv")
    fairnessDataframe = pd.read_csv(result_dir + "fairnessEvaluation_stepsize=" + str(stepsize) + ".csv")
    fairnessDataframe = fairnessDataframe.set_index('pos')
    print("Fairness details are")
    print(fairnessDataframe)
    # plot results
    mpl.rcParams.update({'font.size': 24, 'lines.linewidth': 3,
                         'lines.markersize': 15, 'font.family': 'Times New Roman'})
    mpl.rcParams['ps.useafm'] = True
    mpl.rcParams['pdf.use14corefonts'] = True
    mpl.rcParams['text.usetex'] = True
    ax = fairnessDataframe.plot(y=groupNames,
                                kind='line',
                                use_index=True,
                                rot=45)
    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
    ax.set_xlabel("ranking position")
    ax.set_ylabel("percentage")
    #plt.savefig(result_dir + "fairnessEvaluation_stepsize=" + str(stepsize) + ".png", dpi=100, bbox_inches='tight')

def main():
    # parse command line options
    # first I have to make it work for the independent groups case and check
    # if the barycenter concpt is working in the case of independent set or not.

    parser = argparse.ArgumentParser(prog='Continuous Fairness Algorithm',
                                     epilog="=== === === end === === ===")

    parser.add_argument("--create",
                        nargs=1,
                        choices=['synthetic', 'lsat'],
                        help="creates datasets from raw data and writes them to disk")
    parser.add_argument("--run",
                        nargs=4,
                        metavar=('DATASET NAME', 'STEPSIZE', 'THETAS', 'DIRECTORY'),
                        help="runs continuous fairness algorithm for given DATASET NAME with \
                              STEPSIZE and THETAS and stores results into DIRECTORY")

    parser.add_argument("--runind",
                        nargs=4,
                        metavar=('DATASET NAME', 'STEPSIZE', 'THETAS', 'DIRECTORY'))

    parser.add_argument("--evaluate",
                        nargs=3,
                        metavar=('DATASET NAME', 'PATH TO ORIG DATASET', 'PATH TO RESULT DATASET'),
                        help="evaluates all experiments for respective dataset and \
                              stores results into directory given in PATH TO RESULT DATASET")

    args = parser.parse_args()

    if args.create == ['synthetic']:
        createSyntheticData(100000)
    elif args.create == ['lsat']:
        createLSATDatasets()
    elif args.run:
        score_stepsize = float(args.run[1])
        thetas = [] #parseThetas(args.run[2])
        for i in range(13006):
            thetas.append(1)
        result_dir = args.run[3]
        if args.run[0] == 'synthetic':
            groupNames = {"[0]":"Male",
                          "[1]":"Female",
                          "[2]":"White",
                          "[3]":"Amerindian",
                          "[4]":"Asian",
                          "[5]":"Black",
                          "[6]":"Hispanic",
                          "[7]":"Mexican",
                          "[8]":"Other",
                          "[9]":"Puertorican"}
            rerank_with_cfa(score_stepsize,
                            thetas,
                            result_dir,
                            '../data/synthetic/dataset.csv',
                            '../data/synthetic/groups.csv',
                            'score',
                            groupNames)
        elif args.run[0] == 'lsat_gender':
            # TODO: run experiments also with ZFYA
            groupNames = {"[0]": "Male",
                          "[1]": "Female"}
            rerank_with_cfa(score_stepsize,
                            thetas,
                            result_dir,
                            '../data/LSAT/gender/genderLSAT.csv',
                            '../data/LSAT/gender/genderGroups.csv',
                            'LSAT',
                            groupNames)
        elif args.run[0] == 'lsat_race':
            groupNames = {"[0]":"White",
                          "[1]":"Amerindian",
                          "[2]":"Asian",
                          "[3]":"Black",
                          "[4]":"Hispanic",
                          "[5]":"Mexican",
                          "[6]":"Other",
                          "[7]":"Puertorican"}
            rerank_with_cfa(score_stepsize,
                            thetas,
                            result_dir,
                            '../data/LSAT/allRace/allEthnicityLSAT.csv',
                            '../data/LSAT/allRace/allEthnicityGroups.csv',
                            'LSAT',
                            groupNames)
        else:
            parser.error("unknown dataset. Options are 'synthetic', 'lsat_gender', 'lsat_race'")
    
    elif args.runind:
        score_stepsize = float(args.runind[1])
        #thetas = parseThetas(args.runind[2])
        thetas = [] #parseThetas(args.run[2])
        for i in range(1341):
            thetas.append(1)
        result_dir = args.runind[3]
        if args.runind[0] == "lsat_all":
            groupNames = {"[0,2]":"Male",
                          "[1,2]":"Female",
                          "[0,3]":"White",
                          "[1,3]":"Amerindian",
                          "[0,4]":"Asian",
                          "[1,4]":"Black",
                          "[0,5]":"Hispanic",
                          "[1,5]":"Mexican",
                          "[0,6]":"Other",
                          "[1,6]":"Puertorican",
                          "[0,7]":"S",
                          "[1,7]":"W",
                          "[0,8]":"Q",
                          "[1,8]":"A",
                          "[0,9]":"w",
                          "[1,9]":"R"}
            rerank_with_cfa(score_stepsize,
                           thetas,
                           result_dir,
                           '../data/LSAT/all/allLSAT.csv',
                           '../data/LSAT/all/allGroups.csv',

                           'LSAT',
                           groupNames)

        if args.runind[0] == "pokec_all":
            groupNames = {"[0,0,0,0]":"1",
                          "[1,0,0,0]":"2",
                          "[0,1,0,0]":"3",
                          "[1,1,0,0]":"4",
                          "[0,0,1,1]":"5",
                          "[1,0,1,1]":"6",
                          "[0,1,1,1]":"7",
                          "[1,1,1,1]":"8",
                          "[0,0,0,1]":"9",
                          "[0,1,0,1]":"10",
                          "[1,0,0,1]":"11",
                          "[1,1,0,1]":"12",
                          "[0,0,1,0]":"13",
                          "[0,1,1,0]":"14",
                          "[1,0,1,0]":"15",
                          "[1,1,1,0]":"16"}
            rerank_with_cfa(score_stepsize,
                           thetas,
                           result_dir,
                           '../data/pokec/pokec-z/allPokec.csv',
                           '../data/pokec/pokec-z/allGroups.csv',
                           'score',
                           groupNames)

        elif args.runind[0] == 'pokec_age_gender':
            groupNames = {"[0]":"1",
                          "[1]":"2",
                          "[2]":"3",
                          "[3]":"4",
                          "[4]":"5",
                          "[5]":"6",
                          "[6]":"7",
                          "[7]":"8"}
            rerank_with_cfa(score_stepsize,
                            thetas,
                            result_dir,
                            '../data/pokec/pokec-z/allNBA_country_age.csv',
                            '../data/pokec/pokec-z/allNBA_country_age_Groups.csv',
                            'score',
                            groupNames)



    elif args.evaluate:
        pathToOrigData = args.evaluate[1]
        pathToCFAResult = args.evaluate[2]
        result_dir = os.path.dirname(pathToCFAResult) + '/'
        if args.evaluate[0] == 'synthetic':
            qualAttr = 'score'
            groups = pd.read_csv('../data/synthetic/groups.csv', sep=',')
            groupNames = ["Group [0 0]", "Group [0 1]", "Group [0 2]", "Group [1 0]", "Group [1 1]", "Group [1 2]"]

        if args.evaluate[0] == 'lsat_race':
            qualAttr = 'LSAT'
            groups = pd.read_csv('../data/LSAT/allRace/allEthnicityGroups.csv', sep=',')
            groupNames = ["White", "Amerindian", "Asian", "Black", "Hispanic", "Mexican", "Other", "Puertorican"]

        if args.evaluate[0] == 'lsat_gender':
            qualAttr = 'LSAT'
            groups = pd.read_csv('../data/LSAT/gender/genderGroups.csv', sep=',')
            groupNames = ["Male", "Female"]

        origData = pd.read_csv(pathToOrigData, sep=',')
        fairData = pd.read_csv(pathToCFAResult, sep=',')

        score_stepsize = 1000

        evaluateRelevance(origData, fairData, result_dir, qualAttr, score_stepsize)
        evaluateFairness(fairData, groups, groupNames, result_dir, score_stepsize)
    else:
        parser.error("choose one command line option")


if __name__ == '__main__':
    main()
